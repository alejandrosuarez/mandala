{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing can be weird for some objects\n",
    "Below we illustrate several potentially confusing behaviors that are hard to\n",
    "eradicate in general:\n",
    "- even if we set all random seeds properly, certain computations (e.g., training\n",
    "a `scikit-learn` model) result in objects with non-deterministic content IDs\n",
    "- certain objects can change their content ID after making a roundtrip through\n",
    "the serialization-deserialization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content IDs of the two models: e50ecc81eb3892c1e40a41539d8cf0e1 and 01899c01a78746fd1c554171b1e944fc\n",
      "Content IDs of the original and restored model: e50ecc81eb3892c1e40a41539d8cf0e1 and 549fedf90f84de7c8c77ac26940c7ed6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from mandala.utils import get_content_hash, serialize, deserialize\n",
    "\n",
    "X, y = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "def train_model():\n",
    "    ### set both the numpy and python random seed\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    ### train a model, passing the random_state explicitly\n",
    "    model = RandomForestClassifier(max_depth=2, \n",
    "                                n_estimators=100, random_state=42).fit(X, y)\n",
    "    return model\n",
    "\n",
    "### training in the exact same way will produce different content hashes\n",
    "model_1 = train_model()\n",
    "model_2 = train_model()\n",
    "print(f'Content IDs of the two models: {get_content_hash(model_1)} and {get_content_hash(model_2)}')\n",
    "\n",
    "### a roundtrip serialization will produce a different content hash\n",
    "roundtrip_model_1 = deserialize(serialize(model_1))\n",
    "print(f'Content IDs of the original and restored model: {get_content_hash(model_1)} and {get_content_hash(roundtrip_model_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is this hard to get rid of in general?** One pervasive issue is that some\n",
    "custom Python objects, e.g. many kinds of ML models and even `pytorch` tensors,\n",
    "create internal state related to system resources, such as memory layout. These \n",
    "can be different between objects that otherwise have semantically equivalent\n",
    "state, leading to different content hashes. It is impossible to write down a\n",
    "hash function that always ignores these aspects for arbitrary classes, because \n",
    "we don't know how to interpret which attributes of the object are semantically\n",
    "meaningful and which are contingent.\n",
    "\n",
    "**What should you do about it?** This issue does come up that often in practice.\n",
    "Note that this is not an issue for many kinds of objects, such as primitive\n",
    "Python types and nested python collections thereof, as well as some other types\n",
    "like numpy arrays. If you always pass as inputs to `@op`s objects like this, or\n",
    "`Ref`s obtained from other `@op`s, this issue will not come up. Indeed, if\n",
    "\"unwieldy\" objects are always results of `@op`s, a single copy of each such\n",
    "object will be saved and deserialized every time.\n",
    "\n",
    "This problem does, however, make it very difficult to detect when your `@op`s\n",
    "have side effects."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
