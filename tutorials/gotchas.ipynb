{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If `x == y`, this doesn't guarantee that `x` and `y` will have the same content hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 1 == True? True\n",
      "Is the hash of 1 == the hash of True? False\n",
      "Is 23 == 23.0? True\n",
      "Is the hash of 23 == the hash of 23.0? False\n"
     ]
    }
   ],
   "source": [
    "from mandala.utils import get_content_hash\n",
    "\n",
    "print(f'Is 1 == True? {1 == True}')\n",
    "print(f'Is the hash of 1 == the hash of True? {get_content_hash(1) == get_content_hash(True)}')\n",
    "print(f'Is 23 == 23.0? {23 == 23.0}')\n",
    "print(f'Is the hash of 23 == the hash of 23.0? {get_content_hash(23) == get_content_hash(23.0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing numerical values is sensitive to precision and type\n",
    "All three of the values `42, 42.0, 42.000000001` have different content hashes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d922f805b5eead8c40ee21f14329d6c7\n",
      "ca276c58eef17e13c4f274c9280abc1e\n",
      "b61bb24b62bf6b1ab95506a62843be08\n"
     ]
    }
   ],
   "source": [
    "from mandala.utils import get_content_hash\n",
    "\n",
    "print(get_content_hash(42))\n",
    "print(get_content_hash(42.0))\n",
    "print(get_content_hash(42.00000000001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to define custom types that will be insensitive to types and\n",
    "rounding errors when hashed, but this is currently not implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-deterministic hashes for complex objects\n",
    "Below we illustrate several potentially confusing behaviors that are hard to\n",
    "eradicate in general:\n",
    "- even if we set all random seeds properly, certain computations (e.g., training\n",
    "a `scikit-learn` model) result in objects with non-deterministic content IDs\n",
    "- certain objects can change their content ID after making a roundtrip through\n",
    "the serialization-deserialization pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content IDs of the two models: 8e01b7cc414b11547e75e63c17167246 and 7d5071972e079ed7999473c7b7692543\n",
      "Content IDs of the original and restored model: 8e01b7cc414b11547e75e63c17167246 and b1b27079977cc32e3bd8b2726a1efda0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from mandala.utils import get_content_hash, serialize, deserialize\n",
    "\n",
    "X, y = load_digits(n_class=10, return_X_y=True)\n",
    "\n",
    "def train_model():\n",
    "    ### set both the numpy and python random seed\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    ### train a model, passing the random_state explicitly\n",
    "    model = RandomForestClassifier(max_depth=2, \n",
    "                                n_estimators=100, random_state=42).fit(X, y)\n",
    "    return model\n",
    "\n",
    "### training in the exact same way will produce different content hashes\n",
    "model_1 = train_model()\n",
    "model_2 = train_model()\n",
    "print(f'Content IDs of the two models: {get_content_hash(model_1)} and {get_content_hash(model_2)}')\n",
    "\n",
    "### a roundtrip serialization will produce a different content hash\n",
    "roundtrip_model_1 = deserialize(serialize(model_1))\n",
    "print(f'Content IDs of the original and restored model: {get_content_hash(model_1)} and {get_content_hash(roundtrip_model_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is this hard to get rid of in general?** One pervasive issue is that some\n",
    "custom Python objects, e.g. many kinds of ML models and even `pytorch` tensors,\n",
    "create internal state related to system resources, such as memory layout. These \n",
    "can be different between objects that otherwise have semantically equivalent\n",
    "state, leading to different content hashes. It is impossible to write down a\n",
    "hash function that always ignores these aspects for arbitrary classes, because \n",
    "we don't know how to interpret which attributes of the object are semantically\n",
    "meaningful and which are contingent.\n",
    "\n",
    "**What should you do about it?** This issue does come up that often in practice.\n",
    "Note that this is not an issue for many kinds of objects, such as primitive\n",
    "Python types and nested python collections thereof, as well as some other types\n",
    "like numpy arrays. If you always pass as inputs to `@op`s objects like this, or\n",
    "`Ref`s obtained from other `@op`s, this issue will not come up. Indeed, if\n",
    "\"unwieldy\" objects are always results of `@op`s, a single copy of each such\n",
    "object will be saved and deserialized every time.\n",
    "\n",
    "This problem does, however, make it very difficult to detect when your `@op`s\n",
    "have side effects."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
