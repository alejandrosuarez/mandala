{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Random forest ML project\n",
    "This tutorial will show you how `mandala` works in a small random forest\n",
    "ML project. You'll see how **queriable & composable** memoization is a simple way\n",
    "to achieve the main goals of scientific data management:\n",
    "\n",
    "- **iterate in the simplest way** by just dumping more\n",
    "logic/parameters/experiments on top of the code you already ran. Memoization\n",
    "automatically takes care of loading past results, skipping over past\n",
    "computations, and merging results across compatible versions of your code.\n",
    "\n",
    "- **explore the interdependencies of all saved results incrementally and\n",
    "declaratively** with *computation frames*, generalized dataframes that operate\n",
    "over memoized computation graphs. Expand the computational history of artifacts\n",
    "backward (to what produced them) and/or forward (to experiments that used them),\n",
    "perform high-level operations over slices of storage, and generate dataframes of\n",
    "results for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# recommended way to import mandala functionality\n",
    "from mandala._next.imports import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@op # memoizing decorator\n",
    "def generate_dataset(random_seed=42):\n",
    "    print(f\"Generating dataset...\")\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "@op\n",
    "def train_model(X_train, y_train):\n",
    "    print(f\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, round(model.score(X_train, y_train), 2)\n",
    "\n",
    "@op\n",
    "def eval_model(model, X_test, y_test):\n",
    "    print(f\"Evaluating model...\")\n",
    "    return round(model.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running and iterating on the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline once with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Train accuracy: AtomRef(0.91, hid='8f5...', cid='97b...'),\n",
      "Test accuracy: AtomRef(0.76, hid='57f...', cid='9e5...')\n"
     ]
    }
   ],
   "source": [
    "# in-memory storage for all results in this notebook; use `db_path` to persist\n",
    "# to disk\n",
    "storage = Storage() \n",
    "\n",
    "with storage: # block to make all @ops called inside read/write to a given storage\n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    model, train_acc = train_model(X_train, y_train)\n",
    "    test_acc = eval_model(model, X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_acc},\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all three calls are saved to the storage. `@op`s return **value \n",
    "references**, which wrap a Python object with some storage metadata needed to\n",
    "make the memoization **compose**. To get the underlying object, call\n",
    "`storage.unwrap(ref)`.\n",
    "\n",
    "Thanks to that metadata, when we re-run memoized code, the storage recognizes\n",
    "step-by-step that all work has already been done, and only loads *references* to\n",
    "the results (not the Python objects themselves):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: AtomRef(hid='8f5...', cid='97b...', in_memory=False),\n",
      "Test accuracy: AtomRef(hid='57f...', cid='9e5...', in_memory=False)\n"
     ]
    }
   ],
   "source": [
    "with storage: # same code, but now it only loads pointers to saved results\n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    model, train_acc = train_model(X_train, y_train)\n",
    "    test_acc = eval_model(model, X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_acc},\\nTest accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate directly on top of memoized code and change memoized functions backward-compatibly\n",
    "This also makes it easy to iterate on a project by just adding stuff on top of\n",
    "already memoized code. For example, let's add a new parameter to `train_model`\n",
    "in a way compatible with our current results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with 1 trees...\n",
      "    Train accuracy=AtomRef(hid='8f5...', cid='97b...', in_memory=False),\n",
      "    Test accuracy=AtomRef(hid='57f...', cid='9e5...', in_memory=False)\n",
      "Running with 10 trees...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "    Train accuracy=AtomRef(1.0, hid='760...', cid='b67...'),\n",
      "    Test accuracy=AtomRef(0.94, hid='600...', cid='c3b...')\n",
      "Running with 100 trees...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "    Train accuracy=AtomRef(1.0, hid='ab0...', cid='b67...'),\n",
      "    Test accuracy=AtomRef(0.98, hid='45f...', cid='d15...')\n"
     ]
    }
   ],
   "source": [
    "@op\n",
    "def train_model(X_train, y_train, n_estimators=NewArgDefault(1)):\n",
    "    print(f\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, round(model.score(X_train, y_train), 2)\n",
    "\n",
    "with storage: \n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    for n_estimators in [1, 10, 100]:\n",
    "        print(f\"Running with {n_estimators} trees...\")\n",
    "        model, train_acc = train_model(X_train, y_train, n_estimators=n_estimators)\n",
    "        test_acc = eval_model(model, X_test, y_test)\n",
    "        print(f\"    Train accuracy={train_acc},\\n    Test accuracy={test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add a new argument with a default value wrapped as `NewArgDefault(obj)`,\n",
    "this ensures **backward compatibility**. `mandala` will ignore this parameter\n",
    "when its value equals `obj`, and **fall back to memoized calls that don't\n",
    "provide this argument**. \n",
    "\n",
    "This is why `Training model...` got printed **only two times**, and why the\n",
    "results for `n_estimators=1` are not in memory (`in_memory=False`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons of memoization\n",
    "**Composable memoization is a powerful imperative query interface**: *if* you\n",
    "have the memoized code in front of you, **the code becomes its own storage\n",
    "interface**. You can just retrace it and get references to any intermediate\n",
    "results you want to look at. This is very flexible, because you can add control\n",
    "flow logic to restrict the \"query\". Retracing is cheap, because large objects\n",
    "are not loaded from storage, letting you narrow down your \"query\" before\n",
    "high-bandwidth interaction with the backend.\n",
    "\n",
    "However, **the full memoized code may not always be in front of you**!\n",
    "Especially in larger projects, where it's easy to lose track of what has already\n",
    "been computed, there's a need for a complementary storage interface based on\n",
    "**declarative** principles. We discuss this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the storage with computation frames \n",
    "In cases when memoization-based querying is not enough, `mandala` offers the\n",
    "`ComputationFrame` class. A computation frame is a generalization of the\n",
    "familiar `pandas` dataframe in two main ways:\n",
    "\n",
    "- the \"columns\" of a computation frame represent a **computational graph**, made\n",
    "of variables and operations on them.\n",
    "- the \"rows\" of a computation frame are **computations that (partially) follow\n",
    "the structure of the computational graph**.\n",
    "\n",
    "It's best to illustrate this with some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputationFrame with 5 variable(s) (10 unique refs), 1 operation(s) (3 unique calls)\n",
       "Computational graph:\n",
       "    output_0@output_0, output_1@output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = storage.cf(train_model); cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just got a computation frame (CF) corresponding to a very simple computation\n",
    "graph: it only has one operation, `train_model`, with its associated inputs and\n",
    "outputs. **Output variables are appended with the name of the function output\n",
    "they are connected to**, in order to remove ambiguity in cases when not all\n",
    "outputs of an operation are present in the computational graph.\n",
    "\n",
    "The printout also describes the overall number of `Ref`s and `Call`s represented\n",
    "by this CF. Much like in `pandas`, we can rename the \"columns\" of our\n",
    "computation frame for readability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputationFrame with 5 variable(s) (10 unique refs), 1 operation(s) (3 unique calls)\n",
       "Computational graph:\n",
       "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.rename(vars={'output_0': 'model', 'output_1': 'train_acc'}, inplace=True); cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly extract a dataframe from the CF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples from the computation graph:\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, y_train=y_train, X_train=X_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>y_train</th>\n",
       "      <th>train_model</th>\n",
       "      <th>model</th>\n",
       "      <th>train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='c4f...', hid='5f7...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='ca5...', hid='ac0...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='bb3...', hid='255...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             X_train  n_estimators  \\\n",
       "0  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...          10.0   \n",
       "1  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...           NaN   \n",
       "2  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...         100.0   \n",
       "\n",
       "                                             y_train  \\\n",
       "0  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "1  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "2  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "\n",
       "                                     train_model  \\\n",
       "0  Call(train_model, cid='c4f...', hid='5f7...')   \n",
       "1  Call(train_model, cid='ca5...', hid='ac0...')   \n",
       "2  Call(train_model, cid='bb3...', hid='255...')   \n",
       "\n",
       "                                               model  train_acc  \n",
       "0  (DecisionTreeClassifier(max_features='sqrt', r...       1.00  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...       0.91  \n",
       "2  (DecisionTreeClassifier(max_features='sqrt', r...       1.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back a table, where each row corresponds to a call to `train_model`.\n",
    "Furthermore, the `Call` objects themselves (which contain metadata about the\n",
    "call) appear in the column dedicated to the single operation in the graph.\n",
    "\n",
    "We see that in the `n_estimators` column we have the values `[NaN, 10.0, 100.0]`\n",
    "(in some order), reflecting the fact that we made 1 call to `train_model` before\n",
    "introducing the `n_estimators` argument, and 2 afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring storage by expanding the CF\n",
    "This CF gets much more interesting and useful when we can look into where the\n",
    "inputs to `train_model` came from, and what the outputs were used for. We can\n",
    "add the history of particular variables by calling `expand_back` on the CF, and \n",
    "similarly `expand_forward` shows the operations that consume given variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanding back the inputs:\n",
      "ComputationFrame with 6 variable(s) (11 unique refs), 2 operation(s) (4 unique calls)\n",
      "Computational graph:\n",
      "    X_train@output_0, y_train@output_2 = generate_dataset(random_seed=random_seed)\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)\n",
      "\n",
      "Expanding forward the outputs:\n",
      "ComputationFrame with 6 variable(s) (13 unique refs), 2 operation(s) (6 unique calls)\n",
      "Computational graph:\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)\n",
      "    output_0@output_0 = eval_model(model=model)\n"
     ]
    }
   ],
   "source": [
    "print('Expanding back the inputs:')\n",
    "print(cf.expand_back(varnames=[\"X_train\", \"y_train\"]))\n",
    "print('\\nExpanding forward the outputs:')\n",
    "print(cf.expand_forward(varnames=['model', 'train_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a full expansion (until we can't go back or forward) with the\n",
    "`.expand()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputationFrame with 7 variable(s) (14 unique refs), 3 operation(s) (7 unique calls)\n",
       "Computational graph:\n",
       "    X_train@output_0, y_train@output_2 = generate_dataset(random_seed=random_seed)\n",
       "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)\n",
       "    output_0@output_0 = eval_model(model=model)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_cf = cf.expand()\n",
    "expanded_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the extracted CF represents a \"partial\" computation graph: the\n",
    "variables for `X_test`and `y_test` were not reached during this traversal\n",
    "(though they can be added). Finally, we can (again) extract a dataframe from\n",
    "this CF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples from the computation graph:\n",
      "    X_train@output_0, y_train@output_2 = generate_dataset(random_seed=random_seed)\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, y_train=y_train, X_train=X_train)\n",
      "    output_0@output_0 = eval_model(model=model)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>generate_dataset</th>\n",
       "      <th>train_model</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_model</th>\n",
       "      <th>output_0</th>\n",
       "      <th>train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='c4f...', hid='5f7...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='26d...', hid='ed5...')</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='ca5...', hid='ac0...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='b9e...', hid='c5a...')</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='bb3...', hid='255...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='946...', hid='07b...')</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  random_seed  \\\n",
       "0          10.0           42   \n",
       "1           NaN           42   \n",
       "2         100.0           42   \n",
       "\n",
       "                                    generate_dataset  \\\n",
       "0  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "1  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "2  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "\n",
       "                                     train_model  \\\n",
       "0  Call(train_model, cid='c4f...', hid='5f7...')   \n",
       "1  Call(train_model, cid='ca5...', hid='ac0...')   \n",
       "2  Call(train_model, cid='bb3...', hid='255...')   \n",
       "\n",
       "                                               model  \\\n",
       "0  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "2  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "\n",
       "                                     eval_model  output_0  train_acc  \n",
       "0  Call(eval_model, cid='26d...', hid='ed5...')      0.94       1.00  \n",
       "1  Call(eval_model, cid='b9e...', hid='c5a...')      0.76       0.91  \n",
       "2  Call(eval_model, cid='946...', hid='07b...')      0.98       1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_cf.get_df().drop(columns=['X_train', 'y_train']) # drop to avoid a bit of clutter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using computation frames for high-level operations\n",
    "Finally, we can illustrate the use of computation frames for easy declarative\n",
    "operations over the storage, even in the presence of highly heterogeneous\n",
    "experiments. To make this more interesting, let's train some more models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Training model...\n",
      "Training model...\n",
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "@op\n",
    "def train_model(X_train, y_train,\n",
    "                n_estimators=NewArgDefault(1),\n",
    "                max_depth=NewArgDefault(None) # one more backward-compatible argument\n",
    "                ):\n",
    "    print(f\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, round(model.score(X_train, y_train), 2)\n",
    "\n",
    "with storage: \n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    for n_estimators in [10, 100]:\n",
    "        for max_depth in [1, 2]:\n",
    "            model, train_acc = train_model(X_train, y_train, n_estimators=n_estimators, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We left out the call to `eval_model` on purpose to illustrate how CFs handle\n",
    "heterogeneous and partial computations. \n",
    "\n",
    "As before, we build a big CF by expanding backward and forward from\n",
    "`train_model`, and then extract a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples from the computation graph:\n",
      "    X_train@output_0, y_train@output_2 = generate_dataset(random_seed=random_seed)\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, y_train=y_train, X_train=X_train, max_depth=max_depth)\n",
      "    eval_acc@output_0 = eval_model(model=model)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>generate_dataset</th>\n",
       "      <th>train_model</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_model</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='22f...', hid='f56...')</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='c4f...', hid='5f7...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='26d...', hid='ed5...')</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='4f4...', hid='fe1...')</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='bb3...', hid='255...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='946...', hid='07b...')</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='872...', hid='e61...')</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='002...', hid='561...')</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='ca5...', hid='ac0...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='b9e...', hid='c5a...')</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='4f4...', hid='fe1...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='872...', hid='e61...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='22f...', hid='f56...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, max_featu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='002...', hid='561...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, max_featu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimators  max_depth  random_seed  \\\n",
       "0           10.0        1.0           42   \n",
       "1           10.0        NaN           42   \n",
       "2          100.0        2.0           42   \n",
       "3          100.0        NaN           42   \n",
       "4           10.0        2.0           42   \n",
       "5          100.0        1.0           42   \n",
       "6            NaN        NaN           42   \n",
       "7          100.0        2.0           42   \n",
       "8           10.0        2.0           42   \n",
       "9           10.0        1.0           42   \n",
       "10         100.0        1.0           42   \n",
       "\n",
       "                                     generate_dataset  \\\n",
       "0   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "1   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "2   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "3   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "4   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "5   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "6   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "7   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "8   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "9   Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "10  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "\n",
       "                                      train_model  \\\n",
       "0   Call(train_model, cid='22f...', hid='f56...')   \n",
       "1   Call(train_model, cid='c4f...', hid='5f7...')   \n",
       "2   Call(train_model, cid='4f4...', hid='fe1...')   \n",
       "3   Call(train_model, cid='bb3...', hid='255...')   \n",
       "4   Call(train_model, cid='872...', hid='e61...')   \n",
       "5   Call(train_model, cid='002...', hid='561...')   \n",
       "6   Call(train_model, cid='ca5...', hid='ac0...')   \n",
       "7   Call(train_model, cid='4f4...', hid='fe1...')   \n",
       "8   Call(train_model, cid='872...', hid='e61...')   \n",
       "9   Call(train_model, cid='22f...', hid='f56...')   \n",
       "10  Call(train_model, cid='002...', hid='561...')   \n",
       "\n",
       "                                                model  \\\n",
       "0                                                None   \n",
       "1   (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "2                                                None   \n",
       "3   (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "4                                                None   \n",
       "5                                                None   \n",
       "6   (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "7   (DecisionTreeClassifier(max_depth=2, max_featu...   \n",
       "8   (DecisionTreeClassifier(max_depth=2, max_featu...   \n",
       "9   (DecisionTreeClassifier(max_depth=1, max_featu...   \n",
       "10  (DecisionTreeClassifier(max_depth=1, max_featu...   \n",
       "\n",
       "                                      eval_model  eval_acc  train_acc  \n",
       "0                                           None       NaN       0.59  \n",
       "1   Call(eval_model, cid='26d...', hid='ed5...')      0.94       1.00  \n",
       "2                                           None       NaN       0.84  \n",
       "3   Call(eval_model, cid='946...', hid='07b...')      0.98       1.00  \n",
       "4                                           None       NaN       0.71  \n",
       "5                                           None       NaN       0.70  \n",
       "6   Call(eval_model, cid='b9e...', hid='c5a...')      0.76       0.91  \n",
       "7                                           None       NaN        NaN  \n",
       "8                                           None       NaN        NaN  \n",
       "9                                           None       NaN        NaN  \n",
       "10                                          None       NaN        NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = storage.cf(train_model).expand().rename(vars={'output_0': 'model', 'output_1': 'train_acc', 'output_0_0': 'eval_acc'})\n",
    "# use `lazy_vars` to avoid loading the large arrays which we don't need\n",
    "df = cf.get_df(lazy_vars=['X_train', 'y_train']).drop(columns=['X_train', 'y_train'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the various missing computational paths show up as `NaN`s in the \n",
    "table, under either variables (e.g. `max_depth`) or operations (e.g.\n",
    "`eval_model`). \n",
    "\n",
    "Suppose we want the models where train accuracy was above 0.8 and max depth was 2. \n",
    "We can do this with familiar dataframe operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query('train_acc > 0.8 and max_depth == 2').model.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can manipulate storage by e.g. deleting calls based on this\n",
    "dataframe. For example, we can delete all calls to `train_model` where \n",
    "`train_acc < 0.8`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[02:28:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Dropped <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> calls <span style=\"font-weight: bold\">(</span>and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> from cache<span style=\"font-weight: bold\">)</span>.                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">storage.py:331</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[02:28:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Dropped \u001b[1;36m3\u001b[0m calls \u001b[1m(\u001b[0mand \u001b[1;36m3\u001b[0m from cache\u001b[1m)\u001b[0m.                                              \u001b[2mstorage.py\u001b[0m\u001b[2m:\u001b[0m\u001b[2m331\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples from the computation graph:\n",
      "    X_train@output_0, y_train@output_2 = generate_dataset(random_seed=random_seed)\n",
      "    model@output_0, train_acc@output_1 = train_model(n_estimators=n_estimators, y_train=y_train, X_train=X_train, max_depth=max_depth)\n",
      "    eval_acc@output_0 = eval_model(model=model)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>random_seed</th>\n",
       "      <th>generate_dataset</th>\n",
       "      <th>train_model</th>\n",
       "      <th>model</th>\n",
       "      <th>eval_model</th>\n",
       "      <th>eval_acc</th>\n",
       "      <th>train_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='c4f...', hid='5f7...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='26d...', hid='ed5...')</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='ca5...', hid='ac0...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='b9e...', hid='c5a...')</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='bb3...', hid='255...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>Call(eval_model, cid='946...', hid='07b...')</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='4f4...', hid='fe1...')</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42</td>\n",
       "      <td>Call(generate_dataset, cid='19a...', hid='c3f....</td>\n",
       "      <td>Call(train_model, cid='4f4...', hid='fe1...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_depth  random_seed  \\\n",
       "0          10.0        NaN           42   \n",
       "1           NaN        NaN           42   \n",
       "2         100.0        NaN           42   \n",
       "3         100.0        2.0           42   \n",
       "4         100.0        2.0           42   \n",
       "\n",
       "                                    generate_dataset  \\\n",
       "0  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "1  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "2  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "3  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "4  Call(generate_dataset, cid='19a...', hid='c3f....   \n",
       "\n",
       "                                     train_model  \\\n",
       "0  Call(train_model, cid='c4f...', hid='5f7...')   \n",
       "1  Call(train_model, cid='ca5...', hid='ac0...')   \n",
       "2  Call(train_model, cid='bb3...', hid='255...')   \n",
       "3  Call(train_model, cid='4f4...', hid='fe1...')   \n",
       "4  Call(train_model, cid='4f4...', hid='fe1...')   \n",
       "\n",
       "                                               model  \\\n",
       "0  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "2  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "3                                               None   \n",
       "4  (DecisionTreeClassifier(max_depth=2, max_featu...   \n",
       "\n",
       "                                     eval_model  eval_acc  train_acc  \n",
       "0  Call(eval_model, cid='26d...', hid='ed5...')      0.94       1.00  \n",
       "1  Call(eval_model, cid='b9e...', hid='c5a...')      0.76       0.91  \n",
       "2  Call(eval_model, cid='946...', hid='07b...')      0.98       1.00  \n",
       "3                                          None       NaN       0.84  \n",
       "4                                          None       NaN        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.drop_calls(df.query('train_acc < 0.8').train_model, delete_dependents=True)\n",
    "# now check that the dropped calls are gone\n",
    "cf = storage.cf(train_model).expand().rename(vars={'output_0': 'model', 'output_1': 'train_acc', 'output_0_0': 'eval_acc'})\n",
    "cf.get_df(lazy_vars=['X_train', 'y_train']).drop(columns=['X_train', 'y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"343pt\" height=\"542pt\"\n",
       " viewBox=\"0.00 0.00 342.50 542.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 538)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-538 338.5,-538 338.5,4 -4,4\"/>\n",
       "<!-- train_acc -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>train_acc</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M148,-202C148,-202 104,-202 104,-202 98,-202 92,-196 92,-190 92,-190 92,-178 92,-178 92,-172 98,-166 104,-166 104,-166 148,-166 148,-166 154,-166 160,-172 160,-178 160,-178 160,-190 160,-190 160,-196 154,-202 148,-202\"/>\n",
       "<text text-anchor=\"start\" x=\"100\" y=\"-187\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">train_acc</text>\n",
       "<text text-anchor=\"start\" x=\"108\" y=\"-177\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(4 refs)</text>\n",
       "</g>\n",
       "<!-- random_seed -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>random_seed</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M99,-534C99,-534 31,-534 31,-534 25,-534 19,-528 19,-522 19,-522 19,-510 19,-510 19,-504 25,-498 31,-498 31,-498 99,-498 99,-498 105,-498 111,-504 111,-510 111,-510 111,-522 111,-522 111,-528 105,-534 99,-534\"/>\n",
       "<text text-anchor=\"start\" x=\"27\" y=\"-519\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">random_seed</text>\n",
       "<text text-anchor=\"start\" x=\"47\" y=\"-509\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(1 refs)</text>\n",
       "</g>\n",
       "<!-- generate_dataset -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>generate_dataset</title>\n",
       "<path fill=\"none\" stroke=\"#dc322f\" d=\"M111,-451C111,-451 19,-451 19,-451 13,-451 7,-445 7,-439 7,-439 7,-427 7,-427 7,-421 13,-415 19,-415 19,-415 111,-415 111,-415 117,-415 123,-421 123,-427 123,-427 123,-439 123,-439 123,-445 117,-451 111,-451\"/>\n",
       "<text text-anchor=\"start\" x=\"15\" y=\"-436\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">generate_dataset</text>\n",
       "<text text-anchor=\"start\" x=\"45\" y=\"-426\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#dc322f\">(1 calls)</text>\n",
       "</g>\n",
       "<!-- random_seed&#45;&gt;generate_dataset -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>random_seed&#45;&gt;generate_dataset</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M65,-497.82C65,-487.19 65,-473.31 65,-461.2\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"68.5,-461.15 65,-451.15 61.5,-461.15 68.5,-461.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-472\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">random_seed</text>\n",
       "</g>\n",
       "<!-- y_train -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>y_train</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M44,-368C44,-368 12,-368 12,-368 6,-368 0,-362 0,-356 0,-356 0,-344 0,-344 0,-338 6,-332 12,-332 12,-332 44,-332 44,-332 50,-332 56,-338 56,-344 56,-344 56,-356 56,-356 56,-362 50,-368 44,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-353\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">y_train</text>\n",
       "<text text-anchor=\"start\" x=\"10\" y=\"-343\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(1 refs)</text>\n",
       "</g>\n",
       "<!-- train_model -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>train_model</title>\n",
       "<path fill=\"none\" stroke=\"#dc322f\" d=\"M189,-285C189,-285 129,-285 129,-285 123,-285 117,-279 117,-273 117,-273 117,-261 117,-261 117,-255 123,-249 129,-249 129,-249 189,-249 189,-249 195,-249 201,-255 201,-261 201,-261 201,-273 201,-273 201,-279 195,-285 189,-285\"/>\n",
       "<text text-anchor=\"start\" x=\"125\" y=\"-270\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">train_model</text>\n",
       "<text text-anchor=\"start\" x=\"139\" y=\"-260\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#dc322f\">(4 calls)</text>\n",
       "</g>\n",
       "<!-- y_train&#45;&gt;train_model -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>y_train&#45;&gt;train_model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M47.71,-331.94C58.83,-322.76 73.22,-311.59 87,-303 94.54,-298.3 102.81,-293.76 110.96,-289.6\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"112.68,-292.66 120.08,-285.08 109.57,-286.39 112.68,-292.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"104\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">y_train</text>\n",
       "</g>\n",
       "<!-- model -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>model</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M220,-202C220,-202 190,-202 190,-202 184,-202 178,-196 178,-190 178,-190 178,-178 178,-178 178,-172 184,-166 190,-166 190,-166 220,-166 220,-166 226,-166 232,-172 232,-178 232,-178 232,-190 232,-190 232,-196 226,-202 220,-202\"/>\n",
       "<text text-anchor=\"start\" x=\"187\" y=\"-187\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">model</text>\n",
       "<text text-anchor=\"start\" x=\"187\" y=\"-177\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(4 refs)</text>\n",
       "</g>\n",
       "<!-- eval_model -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>eval_model</title>\n",
       "<path fill=\"none\" stroke=\"#dc322f\" d=\"M233.5,-119C233.5,-119 176.5,-119 176.5,-119 170.5,-119 164.5,-113 164.5,-107 164.5,-107 164.5,-95 164.5,-95 164.5,-89 170.5,-83 176.5,-83 176.5,-83 233.5,-83 233.5,-83 239.5,-83 245.5,-89 245.5,-95 245.5,-95 245.5,-107 245.5,-107 245.5,-113 239.5,-119 233.5,-119\"/>\n",
       "<text text-anchor=\"start\" x=\"172.5\" y=\"-104\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">eval_model</text>\n",
       "<text text-anchor=\"start\" x=\"185\" y=\"-94\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#dc322f\">(3 calls)</text>\n",
       "</g>\n",
       "<!-- model&#45;&gt;eval_model -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>model&#45;&gt;eval_model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M205,-165.82C205,-155.19 205,-141.31 205,-129.2\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"208.5,-129.15 205,-119.15 201.5,-129.15 208.5,-129.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"220.5\" y=\"-140\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">model</text>\n",
       "</g>\n",
       "<!-- max_depth -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>max_depth</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M215.5,-368C215.5,-368 160.5,-368 160.5,-368 154.5,-368 148.5,-362 148.5,-356 148.5,-356 148.5,-344 148.5,-344 148.5,-338 154.5,-332 160.5,-332 160.5,-332 215.5,-332 215.5,-332 221.5,-332 227.5,-338 227.5,-344 227.5,-344 227.5,-356 227.5,-356 227.5,-362 221.5,-368 215.5,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"156.5\" y=\"-353\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">max_depth</text>\n",
       "<text text-anchor=\"start\" x=\"170\" y=\"-343\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(1 refs)</text>\n",
       "</g>\n",
       "<!-- max_depth&#45;&gt;train_model -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>max_depth&#45;&gt;train_model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M181.85,-331.82C178.01,-321.08 172.97,-307.03 168.61,-294.84\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"171.81,-293.39 165.14,-285.15 165.22,-295.75 171.81,-293.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"202.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">max_depth</text>\n",
       "</g>\n",
       "<!-- X_train -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>X_train</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M118,-368C118,-368 86,-368 86,-368 80,-368 74,-362 74,-356 74,-356 74,-344 74,-344 74,-338 80,-332 86,-332 86,-332 118,-332 118,-332 124,-332 130,-338 130,-344 130,-344 130,-356 130,-356 130,-362 124,-368 118,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"82\" y=\"-353\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">X_train</text>\n",
       "<text text-anchor=\"start\" x=\"84\" y=\"-343\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(1 refs)</text>\n",
       "</g>\n",
       "<!-- X_train&#45;&gt;train_model -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>X_train&#45;&gt;train_model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M112.8,-331.74C118.37,-323.02 125.38,-312.33 132,-303 134.22,-299.88 136.6,-296.64 138.99,-293.45\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"141.98,-295.31 145.27,-285.24 136.41,-291.06 141.98,-295.31\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.5\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">X_train</text>\n",
       "</g>\n",
       "<!-- eval_acc -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>eval_acc</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M225.5,-36C225.5,-36 184.5,-36 184.5,-36 178.5,-36 172.5,-30 172.5,-24 172.5,-24 172.5,-12 172.5,-12 172.5,-6 178.5,0 184.5,0 184.5,0 225.5,0 225.5,0 231.5,0 237.5,-6 237.5,-12 237.5,-12 237.5,-24 237.5,-24 237.5,-30 231.5,-36 225.5,-36\"/>\n",
       "<text text-anchor=\"start\" x=\"180.5\" y=\"-21\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">eval_acc</text>\n",
       "<text text-anchor=\"start\" x=\"187\" y=\"-11\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(3 refs)</text>\n",
       "</g>\n",
       "<!-- n_estimators -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>n_estimators</title>\n",
       "<path fill=\"none\" stroke=\"#268bd2\" d=\"M322.5,-368C322.5,-368 257.5,-368 257.5,-368 251.5,-368 245.5,-362 245.5,-356 245.5,-356 245.5,-344 245.5,-344 245.5,-338 251.5,-332 257.5,-332 257.5,-332 322.5,-332 322.5,-332 328.5,-332 334.5,-338 334.5,-344 334.5,-344 334.5,-356 334.5,-356 334.5,-362 328.5,-368 322.5,-368\"/>\n",
       "<text text-anchor=\"start\" x=\"253.5\" y=\"-353\" font-family=\"Helvetica,sans-Serif\" font-weight=\"bold\" font-size=\"10.00\" fill=\"#002b36\">n_estimators</text>\n",
       "<text text-anchor=\"start\" x=\"272\" y=\"-343\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#268bd2\">(2 refs)</text>\n",
       "</g>\n",
       "<!-- n_estimators&#45;&gt;train_model -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>n_estimators&#45;&gt;train_model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M271.72,-332C261.19,-322.73 247.41,-311.45 234,-303 226.32,-298.16 217.87,-293.58 209.49,-289.43\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"210.99,-286.27 200.46,-285.09 207.96,-292.58 210.99,-286.27\"/>\n",
       "<text text-anchor=\"middle\" x=\"280\" y=\"-306\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">n_estimators</text>\n",
       "</g>\n",
       "<!-- generate_dataset&#45;&gt;y_train -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>generate_dataset&#45;&gt;y_train</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M46.99,-414.84C42.4,-409.54 37.93,-403.4 35,-397 32.37,-391.26 30.69,-384.74 29.63,-378.45\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"33.07,-377.75 28.37,-368.25 26.13,-378.61 33.07,-377.75\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">output_2</text>\n",
       "</g>\n",
       "<!-- generate_dataset&#45;&gt;X_train -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>generate_dataset&#45;&gt;X_train</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M72.85,-414.82C77.8,-403.98 84.3,-389.74 89.91,-377.47\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"93.19,-378.7 94.16,-368.15 86.83,-375.79 93.19,-378.7\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.5\" y=\"-389\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">output_0</text>\n",
       "</g>\n",
       "<!-- train_model&#45;&gt;train_acc -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>train_model&#45;&gt;train_acc</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M143.69,-248.87C139.61,-243.48 135.62,-237.29 133,-231 130.57,-225.17 128.97,-218.62 127.92,-212.32\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"131.36,-211.62 126.63,-202.14 124.42,-212.5 131.36,-211.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">output_1</text>\n",
       "</g>\n",
       "<!-- train_model&#45;&gt;model -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>train_model&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M168.76,-248.82C174.98,-237.87 183.16,-223.46 190.17,-211.11\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"193.36,-212.58 195.26,-202.15 187.28,-209.12 193.36,-212.58\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.5\" y=\"-223\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">output_0</text>\n",
       "</g>\n",
       "<!-- eval_model&#45;&gt;eval_acc -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>eval_model&#45;&gt;eval_acc</title>\n",
       "<path fill=\"none\" stroke=\"#002b36\" d=\"M205,-82.82C205,-72.19 205,-58.31 205,-46.2\"/>\n",
       "<polygon fill=\"#002b36\" stroke=\"#002b36\" points=\"208.5,-46.15 205,-36.15 201.5,-46.15 208.5,-46.15\"/>\n",
       "<text text-anchor=\"middle\" x=\"226.5\" y=\"-57\" font-family=\"Helvetica,sans-Serif\" font-size=\"10.00\" fill=\"#002b36\">output_0</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7875f3702440>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30c0510467e0bc33a523a84a8acb20ce0730b8eb0ee254a4b0039140f094f217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
