{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Random forest ML project\n",
    "This tutorial will show you how `mandala` works in a small random forest\n",
    "ML project. You'll see how *queriable & composable* memoization is a simple way\n",
    "to achieve the main goals of scientific data management:\n",
    "- easily iterate by just dumping more logic/parameters/experiments on top of the\n",
    "code you already ran. Memoization automatically takes care of loading past\n",
    "results, skipping over past computations, and merging results across compatible\n",
    "versions of your code.\n",
    "- explore the interdependencies of all saved results incrementally and\n",
    "declaratively with **computation frames**, generalized dataframes that operate\n",
    "over memoized computational graphs. Expand the computational history of\n",
    "artifacts backward (to what produced them) and/or forward (to experiments that\n",
    "used them), and generate dataframes of results for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# recommended way to import mandala functionality\n",
    "from mandala._next.imports import *\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@op # memoizing decorator\n",
    "def generate_dataset(random_seed=42):\n",
    "    print(f\"Generating dataset...\")\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=random_seed)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "@op\n",
    "def train_model(X_train, y_train):\n",
    "    print(f\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, round(model.score(X_train, y_train), 2)\n",
    "\n",
    "@op\n",
    "def eval_model(model, X_test, y_test):\n",
    "    print(f\"Evaluating model...\")\n",
    "    return round(model.score(X_test, y_test), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running and iterating on the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline once with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataset...\n",
      "Training model...\n",
      "Evaluating model...\n",
      "Train accuracy: AtomRef(0.91, hid='8f5...', cid='97b...'), Test accuracy: AtomRef(0.76, hid='57f...', cid='9e5...')\n"
     ]
    }
   ],
   "source": [
    "storage = Storage() # in-memory storage for all results in this notebook\n",
    "\n",
    "with storage: # we make @ops use a given storage with this `with` block \n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    model, train_acc = train_model(X_train, y_train)\n",
    "    test_acc = eval_model(model, X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all three calls are saved to the storage. `@op`s return **value \n",
    "references**, which wrap a Python object with some storage metadata needed to\n",
    "make the memoization **compose**. \n",
    "\n",
    "Thanks to that metadata, when we re-run memoized code, the storage recognizes\n",
    "step-by-step that all work has already been done, and only loads *references* to\n",
    "the results (not the Python objects themselves):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: AtomRef(hid='8f5...', cid='97b...', in_memory=False), Test accuracy: AtomRef(hid='57f...', cid='9e5...', in_memory=False)\n"
     ]
    }
   ],
   "source": [
    "with storage: # same code, but now it only loads pointers to saved results\n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    model, train_acc = train_model(X_train, y_train)\n",
    "    test_acc = eval_model(model, X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate directly on top of memoized code and change memoized functions backward-compatibly\n",
    "This also makes it easy to iterate on a project by just adding stuff on top of\n",
    "already memoized code. For example, let's add a new parameter to `train_model`\n",
    "in a way compatible with our current results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 1 trees: Train accuracy=AtomRef(hid='8f5...', cid='97b...', in_memory=False), Test accuracy=AtomRef(hid='57f...', cid='9e5...', in_memory=False)\n",
      "Training model...\n",
      "Evaluating model...\n",
      "With 10 trees: Train accuracy=AtomRef(1.0, hid='760...', cid='b67...'), Test accuracy=AtomRef(0.94, hid='600...', cid='c3b...')\n",
      "Training model...\n",
      "Evaluating model...\n",
      "With 100 trees: Train accuracy=AtomRef(1.0, hid='ab0...', cid='b67...'), Test accuracy=AtomRef(0.98, hid='45f...', cid='d15...')\n"
     ]
    }
   ],
   "source": [
    "@op\n",
    "def train_model(X_train, y_train, n_estimators=NewArgDefault(1)):\n",
    "    print(f\"Training model...\")\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, round(model.score(X_train, y_train), 2)\n",
    "\n",
    "with storage: # we make @ops use a given storage with this `with` block \n",
    "    X_train, X_test, y_train, y_test = generate_dataset()\n",
    "    for n_estimators in [1, 10, 100]:\n",
    "        model, train_acc = train_model(X_train, y_train, n_estimators=n_estimators)\n",
    "        test_acc = eval_model(model, X_test, y_test)\n",
    "        print(f\"With {n_estimators} trees: Train accuracy={train_acc}, Test accuracy={test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we add a new argument with a default value wrapped as `NewArgDefault(obj)`,\n",
    "`mandala` will ignore this parameter when its value equals `obj`, and fall back\n",
    "on memoized calls that don't provide this argument. \n",
    "\n",
    "This is why `Training model...` got printed only two times, and why the results\n",
    "for `n_estimators=1` are not in memory (`in_memory=False`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons of memoization\n",
    "Composable memoization is a powerful \"imperative\" query interface: if you have\n",
    "the memoized code in front of you, you can just retrace it and get references to\n",
    "any intermediate results you want to look at. This is very flexible, because you\n",
    "can add control flow logic to restrict the results to look at. Retracing is\n",
    "cheap, because large objects are not loaded from storage, letting you narrow\n",
    "down your \"query\" before high-bandwidth interaction with the storage.\n",
    "\n",
    "However, the memoized code may not always be in front of you! Especially in\n",
    "larger projects, where it's easy to lose track of what has already been\n",
    "computed, there's a need for a complementary storage interface based on\n",
    "**declarative** principles. We discuss this next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the storage with computation frames \n",
    "To complement the weaknesses of memoization, `mandala` offers the\n",
    "`ComputationFrame` class. A computation frame is a generalization of the\n",
    "familiar `pandas` dataframe in two main ways:\n",
    "- the \"columns\" of a computation frame represent a **computational graph**, made of \n",
    "variables and operations on them.\n",
    "- the \"rows\" of a computation frame are **computations that (partially) follow\n",
    "the structure of the computational graph**.\n",
    "\n",
    "It's best to illustrate this via some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputationFrame with 5 variable(s) (10 unique refs), 1 operation(s) (3 unique calls)\n",
       "Computational graph:\n",
       "    output_0, output_1 = train_model(y_train=y_train, n_estimators=n_estimators, X_train=X_train)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = storage.cf(train_model)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComputationFrame with 5 variable(s) (10 unique refs), 1 operation(s) (3 unique calls)\n",
       "Computational graph:\n",
       "    model, train_acc = train_model(y_train=y_train, n_estimators=n_estimators, X_train=X_train)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.rename(vars={'output_0': 'model', 'output_1': 'train_acc'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just got a computation frame (CF) corresponding to a very simple computation\n",
    "graph: it only has one operation, `train_model`, with its associated inputs and\n",
    "outputs. The printout also describes the overall number of `Ref`s and `Call`s\n",
    "represented by this CF.\n",
    "\n",
    "We can directly extract a dataframe from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tuples from the computation graph:\n",
      "output_0, output_1 = train_model(n_estimators=n_estimators, X_train=X_train, y_train=y_train)...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>y_train</th>\n",
       "      <th>train_model</th>\n",
       "      <th>output_0</th>\n",
       "      <th>output_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='bb3...', hid='255...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='ca5...', hid='ac0...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...</td>\n",
       "      <td>Call(train_model, cid='c4f...', hid='5f7...')</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             X_train  n_estimators  \\\n",
       "0  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...         100.0   \n",
       "1  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...           NaN   \n",
       "2  [[0.0, 0.0, 3.0, 14.0, 1.0, 0.0, 0.0, 0.0, 0.0...          10.0   \n",
       "\n",
       "                                             y_train  \\\n",
       "0  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "1  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "2  [6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 8, 4, 5, 9, ...   \n",
       "\n",
       "                                     train_model  \\\n",
       "0  Call(train_model, cid='bb3...', hid='255...')   \n",
       "1  Call(train_model, cid='ca5...', hid='ac0...')   \n",
       "2  Call(train_model, cid='c4f...', hid='5f7...')   \n",
       "\n",
       "                                            output_0  output_1  \n",
       "0  (DecisionTreeClassifier(max_features='sqrt', r...      1.00  \n",
       "1  (DecisionTreeClassifier(max_features='sqrt', r...      0.91  \n",
       "2  (DecisionTreeClassifier(max_features='sqrt', r...      1.00  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get back a table, where each row corresponds to a call to `train_model`.\n",
    "Furthermore, the `Call` objects themselves (which contain metadata about the\n",
    "call) appear in the column dedicated to the single operation in the graph.\n",
    "\n",
    "We see that in the `n_estimators` column we have the values `[100.0, NaN, 10.0]`, \n",
    "reflecting the fact that we made 1 call to `train_model` before introducing the\n",
    "`n_estimators` argument, and 2 afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring storage by expanding the CF\n",
    "This CF gets much more interesting and useful when we can look into where the\n",
    "inputs to `train_model` came from, and what the outputs were used for. We can\n",
    "add the history of particular variables by calling `expand_back` on the CF, and \n",
    "similarly `expand_forward` shows the operations that consume given variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComputationFrame with 6 variable(s) (11 unique refs), 2 operation(s) (4 unique calls)\n",
      "Computational graph:\n",
      "    X_train, y_train = generate_dataset(random_seed=random_seed)\n",
      "    output_0, output_1 = train_model(y_train=y_train, n_estimators=n_estimators, X_train=X_train)\n"
     ]
    }
   ],
   "source": [
    "print(cf.expand_back(varnames=[\"X_train\", \"y_train\"]))\n",
    "print(cf.expand_forward(varnames=['output_0', 'output_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30c0510467e0bc33a523a84a8acb20ce0730b8eb0ee254a4b0039140f094f217"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
