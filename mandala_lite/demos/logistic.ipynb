{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression in pytorch\n",
    "## What's in this tutorial?\n",
    "This notebook will walk you through the most basic use of `mandala` for storing\n",
    "and tracking ML experiment results. It uses logistic regression on MNIST as a\n",
    "\"minimally interesting\" example. By following this mini-project, you will learn\n",
    "how to\n",
    "- break up an experiment into Python functions whose calls can be tracked and\n",
    "queried;\n",
    "- use memoization to avoid re-running expensive computations and to\n",
    "naturally interact with and grow your project (by adjusting the parameters and\n",
    "adding new code);\n",
    "- get a powerful query interface to your results \"for free\" by repurposing the\n",
    "  pure Python code of your experiments.\n",
    "\n",
    "The overall goal that `mandala` enables is to let you write only the\n",
    "plain-Python code you'd write if you were just running experiments in-memory -\n",
    "yet get the benefits of a database-backed experiment tracking system that knows\n",
    "not to recompute already computed quantities, and is aware of the relationships\n",
    "between these quantities and the parameters that went into them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project description\n",
    "As the example project, you will use logistic regression to classify MNIST\n",
    "digits. On a high level, you'll do the following:\n",
    "- load the train and test sets;\n",
    "- define the model, loss function, and optimizer;\n",
    "- explore the space of hyperparameters (learning rate, batch size, ...) to \n",
    "find a good combination;\n",
    "- iterate on this pipeline until you're satisfied with the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch.utils as utils\n",
    "\n",
    "# recommended way to import mandala functionality\n",
    "from mandala_lite.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define supporting functions\n",
    "For the purposes of this tutorial, you'll break the project into two main\n",
    "functions:\n",
    "- `get_dataloaders` returns `DataLoader`s for the train and test sets with a\n",
    "given batch size;\n",
    "- `train_model` is passed these `DataLoader`s, trains a model on the train set\n",
    "with given hyperparameters, and returns the accuracy on the test set.\n",
    "\n",
    "This kind of decomposition of the problem is a good practice in ML in general,\n",
    "but also when using `mandala` in particular. It allows you to re-use the same\n",
    "intermediate results in different experiments. For example, you might want to\n",
    "try different models on the same data, or different data on the same model. With\n",
    "this decomposition, you can just call `get_dataloaders` once, and then call \n",
    "`train_model` with different models and hyperparameters.\n",
    "\n",
    "Below are definitions of these functions in fairly standard `pytorch` code. Note\n",
    "the use of `@op` to mark the functions as tracked by `mandala` - more on this\n",
    "in a moment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST constants\n",
    "INPUT_SIZE = 28**2\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "\n",
    "@op\n",
    "def get_dataloaders(batch_size: int = 100) -> Tuple[DataLoader, DataLoader]:\n",
    "    # get train and test loaders for the MNIST dataset\n",
    "    train_data = Subset(\n",
    "        MNIST(\"data\", train=True, download=True, transform=tv.transforms.ToTensor()),\n",
    "        indices=range(2_000),\n",
    "    )\n",
    "    test_data = MNIST(\"data\", train=False, transform=tv.transforms.ToTensor())\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A single `pytorch` linear layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(INPUT_SIZE, NUM_CLASSES)\n",
    "\n",
    "    def forward(self, feature):\n",
    "        output = self.linear(feature)\n",
    "        return output\n",
    "\n",
    "\n",
    "@op\n",
    "def train_model(\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    learning_rate: float = 0.001,\n",
    "    num_epochs: int = 5,\n",
    ") -> Tuple[LogisticRegression, float]:\n",
    "    # train a logistic regression model with the given loaders and hyperparameters\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LogisticRegression().to(device)\n",
    "    loss = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        for batch_index, (images, labels) in enumerate(train_loader):\n",
    "            images = images.view(-1, INPUT_SIZE).to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss_value = loss(output, labels)\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "        # test\n",
    "        accurate, total = 0, 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(-1, INPUT_SIZE).to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += labels.size(0)\n",
    "            accurate += (predicted == labels).sum()\n",
    "        acc = 100 * accurate / total\n",
    "        print(\n",
    "            f\"Epoch: {epoch}, Training loss: {round(loss_value.item(), 2)}. Test accuracy: {round(acc.item(), 2)}\"\n",
    "        )\n",
    "    return model, round(float(acc.item()), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the \"default\" experiment and log the results\n",
    "Now that you have defined the functions that make up your experiment, you can\n",
    "run it with the default parameters and log the results. The `@op` decorator on\n",
    "the functions above tells `mandala` to track the calls to these functions, and\n",
    "to store the results in the database - but this only happens when you call these\n",
    "functions in the context of a given *storage*. So go ahead and create a storage\n",
    "for this project: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = Storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This storage will hold the results of all the experiments you run in this\n",
    "notebook. With the storage created, you can run the pipeline and log the results\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training loss: 2.28. Test accuracy: 12.76\n",
      "Epoch: 1, Training loss: 2.26. Test accuracy: 16.09\n",
      "Epoch: 2, Training loss: 2.27. Test accuracy: 19.58\n",
      "Epoch: 3, Training loss: 2.24. Test accuracy: 23.42\n",
      "Epoch: 4, Training loss: 2.2. Test accuracy: 27.18\n",
      "Final accuracy: ValueRef(27.18, uid=5480f19d29d345a1174392cca86057a649b6d0e480cf4130eb9509193ab1e6c01b9605377ef2a568f74119c805d59194a62fdd320030bd1bb3618f1ad3a09249)\n"
     ]
    }
   ],
   "source": [
    "with storage.run():\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "    model, acc = train_model(train_loader, test_loader)\n",
    "    print(f\"Final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What just happened?\n",
    "There is a lot to unpack in these few lines:\n",
    "- The `storage.run()` context manager tells `mandala` that all the calls to the\n",
    "functions decorated with `@op` inside this context should be tracked and stored.\n",
    "- In this context, each time an `@op`-decorated function is called for the first\n",
    "time on a set of inputs, `mandala` stores the inputs and outputs of this call in\n",
    "the storage. \n",
    "- Values shared between calls are stored only once. So\n",
    "  `train_loader` will appear in storage as both the output to the call to\n",
    "  `get_dataloaders`, and the input to the call to `train_model`.\n",
    "- The `acc` object (like all objects returned by `@op`-decorated functions is a\n",
    "*value reference*, which is a value wrapped with storage-relevant metadata.\n",
    "\n",
    "So what happens when you call `@op`-decorated functions a second time on the\n",
    "same inputs? Find out by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: ValueRef(27.18, uid=5480f19d29d345a1174392cca86057a649b6d0e480cf4130eb9509193ab1e6c01b9605377ef2a568f74119c805d59194a62fdd320030bd1bb3618f1ad3a09249)\n"
     ]
    }
   ],
   "source": [
    "with storage.run():\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "    model, acc = train_model(train_loader, test_loader)\n",
    "    print(f\"Final accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this time the code ran much faster. This is because `mandala`\n",
    "recognized that the inputs to the functions were the same as before, and so it\n",
    "didn't need to re-run the calls. This is also evident from the lack of output\n",
    "from the model training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore parameters while reusing past results\n",
    "Where `mandala` really shines is in the ability to minimally change the code of\n",
    "your experiment to efficiently explore different parameters, add new logic on\n",
    "top of a workflow, and query existing results. Let's see how this works by\n",
    "exploring the effect of the learning rate on the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===End of run=== learning_rate: 0.001, acc: 27.18\n",
      "Epoch: 0, Training loss: 2.12. Test accuracy: 45.78\n",
      "Epoch: 1, Training loss: 1.92. Test accuracy: 61.59\n",
      "Epoch: 2, Training loss: 1.84. Test accuracy: 68.46\n",
      "Epoch: 3, Training loss: 1.68. Test accuracy: 71.69\n",
      "Epoch: 4, Training loss: 1.56. Test accuracy: 73.57\n",
      "===End of run=== learning_rate: 0.01, acc: 73.57\n",
      "Epoch: 0, Training loss: 1.23. Test accuracy: 78.13\n",
      "Epoch: 1, Training loss: 0.86. Test accuracy: 81.3\n",
      "Epoch: 2, Training loss: 0.75. Test accuracy: 83.19\n",
      "Epoch: 3, Training loss: 0.62. Test accuracy: 84.03\n",
      "Epoch: 4, Training loss: 0.6. Test accuracy: 85.13\n",
      "===End of run=== learning_rate: 0.1, acc: 85.13\n"
     ]
    }
   ],
   "source": [
    "with storage.run():\n",
    "    train_loader, test_loader = get_dataloaders()\n",
    "    for learning_rate in [0.001, 0.01, 0.1]:\n",
    "        model, acc = train_model(train_loader, test_loader, learning_rate)\n",
    "        print(\n",
    "            f\"===End of run=== learning_rate: {learning_rate}, acc: {round(unwrap(acc), 2)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the higher the learning rate, the better the final accuracy. Now,\n",
    "let's try varying the batch size as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===End of run=== batch_size: 100, learning_rate: 0.001, acc: 27.18\n",
      "===End of run=== batch_size: 100, learning_rate: 0.01, acc: 73.57\n",
      "===End of run=== batch_size: 100, learning_rate: 0.1, acc: 85.13\n",
      "Epoch: 0, Training loss: 2.32. Test accuracy: 13.79\n",
      "Epoch: 1, Training loss: 2.29. Test accuracy: 15.01\n",
      "Epoch: 2, Training loss: 2.28. Test accuracy: 16.4\n",
      "Epoch: 3, Training loss: 2.28. Test accuracy: 17.9\n",
      "Epoch: 4, Training loss: 2.27. Test accuracy: 19.61\n",
      "===End of run=== batch_size: 200, learning_rate: 0.001, acc: 19.61\n",
      "Epoch: 0, Training loss: 2.2. Test accuracy: 29.91\n",
      "Epoch: 1, Training loss: 2.1. Test accuracy: 47.85\n",
      "Epoch: 2, Training loss: 2.02. Test accuracy: 57.92\n",
      "Epoch: 3, Training loss: 1.91. Test accuracy: 64.49\n",
      "Epoch: 4, Training loss: 1.83. Test accuracy: 68.17\n",
      "===End of run=== batch_size: 200, learning_rate: 0.01, acc: 68.17\n",
      "Epoch: 0, Training loss: 1.59. Test accuracy: 74.63\n",
      "Epoch: 1, Training loss: 1.18. Test accuracy: 78.29\n",
      "Epoch: 2, Training loss: 0.98. Test accuracy: 80.65\n",
      "Epoch: 3, Training loss: 0.89. Test accuracy: 81.99\n",
      "Epoch: 4, Training loss: 0.74. Test accuracy: 82.81\n",
      "===End of run=== batch_size: 200, learning_rate: 0.1, acc: 82.81\n",
      "Epoch: 0, Training loss: 2.34. Test accuracy: 11.94\n",
      "Epoch: 1, Training loss: 2.32. Test accuracy: 12.54\n",
      "Epoch: 2, Training loss: 2.33. Test accuracy: 13.2\n",
      "Epoch: 3, Training loss: 2.31. Test accuracy: 13.76\n",
      "Epoch: 4, Training loss: 2.3. Test accuracy: 14.46\n",
      "===End of run=== batch_size: 400, learning_rate: 0.001, acc: 14.46\n",
      "Epoch: 0, Training loss: 2.29. Test accuracy: 14.07\n",
      "Epoch: 1, Training loss: 2.24. Test accuracy: 20.18\n",
      "Epoch: 2, Training loss: 2.18. Test accuracy: 28.75\n",
      "Epoch: 3, Training loss: 2.12. Test accuracy: 39.5\n",
      "Epoch: 4, Training loss: 2.08. Test accuracy: 47.5\n",
      "===End of run=== batch_size: 400, learning_rate: 0.01, acc: 47.5\n",
      "Epoch: 0, Training loss: 1.95. Test accuracy: 65.23\n",
      "Epoch: 1, Training loss: 1.62. Test accuracy: 73.67\n",
      "Epoch: 2, Training loss: 1.39. Test accuracy: 76.08\n",
      "Epoch: 3, Training loss: 1.21. Test accuracy: 78.49\n",
      "Epoch: 4, Training loss: 1.08. Test accuracy: 79.42\n",
      "===End of run=== batch_size: 400, learning_rate: 0.1, acc: 79.42\n"
     ]
    }
   ],
   "source": [
    "with storage.run():\n",
    "    for batch_size in [100, 200, 400]:\n",
    "        train_loader, test_loader = get_dataloaders(batch_size=batch_size)\n",
    "        for learning_rate in [0.001, 0.01, 0.1]:\n",
    "            model, acc = train_model(train_loader, test_loader, learning_rate)\n",
    "            print(\n",
    "                f\"===end of run=== batch_size: {batch_size}, learning_rate: {learning_rate}, acc: {round(unwrap(acc), 2)}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the results\n",
    "By now, you have run the pipeline with many different combinations of\n",
    "parameters, and it's getting difficult to make sense of all the results so far.\n",
    "One option to get to the results is to just re-run the above workflow, or a \"sub-workflow\"\n",
    "of it. For example, how might you get all the results for a given learning rate,\n",
    "e.g. `learning_rate=0.1`?\n",
    "\n",
    "One answer: just by re-running the subset of the above code using this value of\n",
    "the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===end of run=== batch_size: 100, learning_rate: 0.1, acc: 85.13\n",
      "===end of run=== batch_size: 200, learning_rate: 0.1, acc: 82.81\n",
      "===end of run=== batch_size: 400, learning_rate: 0.1, acc: 79.42\n"
     ]
    }
   ],
   "source": [
    "with storage.run():\n",
    "    for batch_size in [100, 200, 400]:\n",
    "        train_loader, test_loader = get_dataloaders(batch_size=batch_size)\n",
    "        for learning_rate in [0.1]:  # only change relative to previous cell\n",
    "            model, acc = train_model(train_loader, test_loader, learning_rate)\n",
    "            print(\n",
    "                f\"===end of run=== batch_size: {batch_size}, learning_rate: {learning_rate}, acc: {round(unwrap(acc), 2)}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of storage access pattern is called **retracing**: you \"retrace\"\n",
    "computational code that you have already run before in order to recover the\n",
    "quantities computed along the way. You can use retracing to *imperatively* query\n",
    "existing results (like you did above), or to easily add new parameters/logic\n",
    "that need to compute over existing results.\n",
    "\n",
    "However, sometimes you don't have a specific piece of code to retrace and just\n",
    "want to look at all the results in storage. For this, you can use a\n",
    "*declarative* query interface via the `storage.query()` context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.100</td>\n",
       "      <td>85.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200</td>\n",
       "      <td>0.100</td>\n",
       "      <td>82.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>79.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>0.010</td>\n",
       "      <td>73.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>0.010</td>\n",
       "      <td>68.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>400</td>\n",
       "      <td>0.010</td>\n",
       "      <td>47.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>27.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.001</td>\n",
       "      <td>19.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>0.001</td>\n",
       "      <td>14.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  learning_rate  accuracy\n",
       "3         100          0.100     85.13\n",
       "8         200          0.100     82.81\n",
       "4         400          0.100     79.42\n",
       "6         100          0.010     73.57\n",
       "2         200          0.010     68.17\n",
       "7         400          0.010     47.50\n",
       "0         100          0.001     27.18\n",
       "5         200          0.001     19.61\n",
       "1         400          0.001     14.46"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with storage.query() as q:\n",
    "    batch_size = Q().named(\"batch_size\")\n",
    "    train_loader, test_loader = get_dataloaders(batch_size=batch_size)\n",
    "    learning_rate = Q().named(\"learning_rate\")\n",
    "    model, acc = train_model(train_loader, test_loader, learning_rate)\n",
    "    df = q.get_table(batch_size, learning_rate, acc.named(\"accuracy\"))\n",
    "\n",
    "df.sort_values(by=[\"accuracy\"], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e39bb3b1f45b78879464f3858f3ac405da62799496d9b7e0a39caf0b676c9a45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
